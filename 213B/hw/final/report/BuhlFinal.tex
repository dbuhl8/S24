\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=blue,
    pdftitle={Overleaf Example},
    }

\title{Final Report}
\author{Dante Buhl}

\DeclareMathOperator{\cond}{cond}
\DeclareMathOperator{\vecspan}{span}


\begin{document}

\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\bmp}[1]{\begin{minipage}{#1\textwidth}}
\newcommand{\emp}{\end{minipage}}
\newcommand{\R}{\mathbb{R}}
%\newcommand{\Imag}{\mathbb{I}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\K}{\bs{\mathrm{K}}}
\newcommand{\m}{\bs{\mu}_*}
\newcommand{\s}{\bs{\Sigma}_*}
\newcommand{\dt}{\Delta t}
\newcommand{\dr}{\Delta r}
\newcommand{\dx}{\Delta x}
\newcommand{\tr}[1]{\text{Tr}(#1)}
\newcommand{\Tr}[1]{\text{Tr}(#1)}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}


\maketitle

\section*{Question 1: Bessels Function Solution}
    \begin{align}
        \begin{cases}
            U_t = \nu\left(U_{rr} +\frac{1}{r}U_{r}\right) \quad \quad r \in [1,
            3],
            \quad t \ge 0\\
            U(r,0) = 15(r-r_1)^2(r_2-r)^2e^{-\sin(2r)-r}\\
            U(1,t) = 0\\
            U(3,t) = 0
        \end{cases} \\
        r_1 = 1, \quad r_2 = 3, \quad \nu = \frac{1}{4}
    \end{align}

\begin{enumerate}[label=\alph*)]

    \item Plot the solution keeping 60 modes of the bessels function expansion
    at times 0, 0.5, 1, 2. As seen in figure 1, the solution decays in time as
    expected from a heat equation in cylindrical coordinates since the heat
    seems to dissipate faster on the outer rim of the cylinder, which is typical
    since there is more surface area on the outer rim. 
    \begin{figure}[ht]
        \centering
        \includegraphics[width=.8\textwidth]{ua_t.png}
        \caption{Plot of Truncated Bessels Solution at $t = [0,0.5,1,2]$}
    \end{figure}

    \item In figure 2, the basis functions $\hat{R_n}$ can be seen for values $n
    = [1,2,4,6]$. As we can see the number of nodes for each function is equal
    to $n + 1$ as it should be. We can also see that all functions have zeros at
    the endpoints of the domain which is lovely. In figure 3, a plot of the
    normalizing factor can be seen to increase with mode number. 
    \begin{figure}[ht]
        \centering
        \includegraphics[width=.8\textwidth]{r.png}
        \caption{Plot of 4 of the basis functions, $R_1, R_2, R_4, R_6$.}
    \end{figure}
    \begin{figure}[ht]
        \centering
        \includegraphics[width=.8\textwidth]{r_norm.png}
        \caption{Normalizing Factors $||\hat{R_k}||_{L_w^2}$ versus k}
    \end{figure}

\end{enumerate}

\section*{Question 2: Finite Differences Solution}
\begin{enumerate}[label=\alph*)]

    \item Write the matrix $M$ explicitly
    \begin{align*}
        M = \nu D_2 + \nu \frac{1}{r}D_1\\
    \end{align*}
    Where $D_1$ and $D_2$ are the standard second order finite difference
    differentiation matrices (non-periodic).
    \begin{align*}
        M = \nu\left[\begin{array}{c c c c c}
            \frac{-2}{\Delta r^2} & \frac{1}{\Delta r^2} + \frac{1}{2r\Delta r} &
            0 & 0 & \cdots  \\
            \frac{1}{\Delta r^2} - \frac{1}{2r\Delta r} &
            \frac{-2}{\Delta r^2} & \frac{1}{\Delta r^2} + \frac{1}{2r\Delta r} &
            0  & \cdots \\
            0 & \frac{1}{\Delta r^2} - \frac{1}{2r\Delta r} &
            \frac{-2}{\Delta r^2} & \frac{1}{\Delta r^2} + \frac{1}{2r\Delta r} &
             \\
            0 & 0 &\frac{1}{\Delta r^2} - \frac{1}{2r\Delta r} &
            \frac{-2}{\Delta r^2} & \ddots\\
            \vdots & \vdots &  & \ddots & \ddots 
            \end{array}\right]
    \end{align*}

    \item Compute the spectral radius of $M$. 
    This is done using an eigenvalue solver, I use LAPACK's DGEEV routine for
    general, non-symmetric matrices. I find that the spectral radius increases
    with n/k.
    \begin{figure}[ht]
        \centering
        \includegraphics[width=.8\textwidth]{spectal.png}
        \caption{Plot of $\rho(M)$ versis gridsize}
    \end{figure}

    \item Find the critical value of $dt$ according to the problem. It can be
    seen in figure 5 that $\dt^*$ decreases in order 2 with respect to the
    number of gridpoints. Seen in the plot along side the data in purple is an
    order 2 decay line in green and an order 3 decay line in blue. It is very
    clear that the purple line is nearly parallel with the green one indicating
    order 2 decay in $\dt^*$. Furthermore, the data also suggests that at
    gridsize $n=200$ that the critical value of $\dt^*$ is equal to
    $0.00005509\ldots$. 
        \begin{proof}
            First we must show that the conditional absolute stability of this
            scheme. We begin by looking at the characteristic polynomial of this
            method. We have, 
            \begin{align*}
                u^{k+1} = u^{k} + \frac{\dt}{12}\bs{M}\left(23u^{k} - 16u^{k-1}
                + 5u^{k-2}\right)
                \tag{AB3}\\
                z^3 - z^2 = \lambda\dt\left(\frac{23z^2 - 16z + 5}{12}\right)
            \end{align*}   
            \begin{align*}
                \dt = \frac{12}{\lambda}\left(\frac{z^3 - z^2}{23z^2 - 16z +
                5}\right)\\
                \dt = \frac{12}{\lambda}\left(\frac{e^{3i\theta} -
                e^{2i\theta}}{23e^{2i\theta} - 16e^{i\theta} +
                5}\right)
            \end{align*}
            Now in order to show that this fraction when colinear with the
            largest eigenvalue of $\bs{M}$ has a maxinum of $\frac{6}{11}$ we must consider two things, first
            the largest eigenvalue of $\bs{M}$ which we will show analytically
            to be real valued, and a constrianed optimization problem for
            $\frac{\rho(z)}{\sigma(z)}$. First we consider the eigenvalues of
            $\bs{M}$. One will first notice the Tridiagonal form of $\bs{M}$.
            This is a special form of a matrix, and furthermore the matrix is
            also known to have a ``Toeplitz'' form. Theese two properties combined
            have been shown to produce an analytical form for the eigenvalues of
            that matrix. As seen in
            \href{https://hal.science/hal-01461924/file/KST.pdf}{a paper by Kulkarni, Schmidt, and
            Tsui}, the
            eigenvalaues of Tridiagonal (pseudo-)Toeplitz matrices have the
            following form, 
            \begin{align*}
                \lambda = a - 2\sqrt{bc}\cos\left(\frac{i\pi}{n+1}\right), \quad
                i = 1, \ldots, n\\
                a = \frac{-2}{\dr^2}, \quad b = \frac{1}{\dr^2} +
                \frac{1}{2r\dr}, \quad c = \frac{1}{\dr^2} -
                \frac{1}{2r\dr}\\
                bc = \frac{1}{\dr^4} - \frac{1}{2r\dr^3} + \frac{1}{2r\dr^3} -
                \frac{1}{4r^2\dr^2}\\
                bc = \frac{1}{\dr^4} - \frac{1}{4r^2\dr^2}
            \end{align*}
            Now we notice that if $\dr << 1$ then $\frac{1}{\dr^4} >>
            \frac{1}{\dr^2}$, which implies that $\sqrt{bc}$ is a real valued
            quantity, and therefore so is each value of $\lambda$ for this
            matrix $\bs{M}$. 

            Next we look for all of the real-valued minimums (minimums because
            $\lambda$ is bounded to be negative by its given form). In order to
            do this we will consider only Re$\left(\frac{\rho(z)}{\sigma(z)}\right)$. 
            \begin{align*}
                \rho(x+iy) = x^3 - xy^2 - x^2 + y^2 + i(x^2y - y^3 -xy)\\
                \sigma(x+iy) = 23x^2 - 23y^2 - 16x + 5 + i\left(46xy -
                16y\right)\\
                \text{Re}\left(\frac{\rho(z)}{\sigma(z)}\right) =
                \text{Re}\left(\frac{\rho(z)\bar{\sigma}(z)}{\sigma(z)\bar{\sigma}(z)}\right)\\
            \end{align*}
            \begin{align*}
                f(x,y) = \text{Re}\left(\frac{\rho(z)}{\sigma(z)}\right) &= \frac{(23x^2 -
                23y^2 - 16x + 5)(x^3 - xy^2 - x^2 + y^2) - \left(46xy -  16y\right)\left(x^2y - y^3 -xy\right)}
                {(23x^2 - 23y^2 - 16x + 5)^2 + \left(46xy - 16y\right)^2}\\
                L(x,y,\mu) &= f(x,y) - \mu(x^2 + y^2 - 1)\\
                L_x &= 0, \quad L_y = 0, \quad L_{\lambda} = 0
            \end{align*}
            \begin{align*}
                \frac{(23z^2-16z+5)(3z^2 - 2z) - (46z - 16)(z^3 - z^2)}{(23z^2 - 16z +
                5)^2 } = 0\\
                (23z^2-16z+5)(3z^2 - 2z) - (46z - 16)(z^3 - z^2) = 0\\
                69z^4 - 48z^3 + 15z^2 - 46z^3 +32z^2 - 10z - 46z^4 + 16z^3 +
                46z^3 - 16z^2 = 0\\
                23z^4 - 32 z^3 + 31z^2 - 10z = 0\\
                23(x+iy)^3 - 32(x+iy)^2 + 31(x+iy) - 10 = 0
            \end{align*}
            You know, I actually don't really want to solve this one haha. Its
            only worth 10 points and I've already shown that $\dt^*$ decays with
            order 2 with respect to gridsize and in previous homework there is
            numerical evidence which suggests that the real valued mininum of
            this complex function has a value of $-\frac{6}{11}$ at $z=-1$. Once it is
            shown that the real valued minimum of this function is -6/11
            the rest of the proof proceeds from this logic. 
            \begin{align*}
                \dt^* = \min_{|z| = 1} \left(\frac{\rho(z)}{\sigma(z)}\right)
                (\text{sign of }\lambda)\frac{1}{\max(|\lambda|)} =
                \frac{6}{11\rho(\bs{M})}
            \end{align*}
        \end{proof}
        \begin{figure}[ht]
            \centering
            \includegraphics[width=.8\textwidth]{dt.png}
            \caption{Plot of $\dt^*$ versis gridsize}
        \end{figure}

    \item Integrate using AB3 and plot the maximum pointwise error. As seen in
    figure 6, the Maximum pointwise error seems to decline as the gridsize
    increases. Note that all 4 lines plotted start at essentially the same value
    of error and quickly diverge into different orders of accuracy. It should
    also be noted that the inherent error in the system at $t = 0$ is around the order of
    $10^{-3}$ or $10^{-4}$ with only 60 bessels modes.
        \begin{figure}[ht]
            \centering
            \includegraphics[width=.8\textwidth]{mpe.png}
            \caption{Maximum Pointwise Error between Truncated Solution and
            Numerical Solution}
        \end{figure}

    \item Plot the final error as a function of times. It can be seen in figure
    7, that the maximum pointwise error at $t = 2$ is dependent on the gridsize.
    It can be seen in the plot that compared with order 2 decay (the green
    line), that this error decays with order 2 in the gridsize. 
        \begin{figure}[ht]
            \centering
            \includegraphics[width=.8\textwidth]{final_mpe.png}
            \caption{Plot of $e_n(2)$ versus n alongside $n^{-2}$}
        \end{figure}


\end{enumerate}

\section*{Question 3: Prove Second Order Accuracy in $\Delta r$}

\begin{enumerate}[label=\alph*)]

    \item We prove that this finite differnce discretization is second order
    accurate in $\Delta r$. To do this we look at the taylor expansions of $U$. 
    \begin{proof}
        As said already. we beign with the Taylor Expansions.
        \begin{align*}
            y_{j-1} = y_j - \Delta r \left(\frac{\partial y}{\partial r}\right)_j
            + \frac{\Delta r^2}{2}\left(\frac{\partial^2 y}{\partial
            r^2}\right)_j - \frac{\Delta r^3}{6}\left(\frac{\partial^3 y}{\partial
            r^3}\right)_j + \frac{\Delta r^4}{24}\left(\frac{\partial^4 y}{\partial
            r^4}\right)_j\\
            y_{j+1} = y_j + \Delta r \left(\frac{\partial y}{\partial r}\right)_j
            + \frac{\Delta r^2}{2}\left(\frac{\partial^2 y}{\partial
            r^2}\right)_j + \frac{\Delta r^3}{6}\left(\frac{\partial^3 y}{\partial
            r^3}\right)_j + \frac{\Delta r^4}{24}\left(\frac{\partial^4 y}{\partial
            r^4}\right)_j
        \end{align*}
        We then substitute these taylor expansions into the finite difference
        scheme and solve for the local truncation error. The result is, 
        \begin{align*}
            \tau_j +  \left(\frac{\partial^2 y}{\partial
            r^2}\right)_j + \frac{1}{r_j}\left(\frac{\partial y}{\partial
            r}\right)_j = \frac{\Delta r^2\left(\frac{\partial^2 y}{\partial
            r^2}\right)_j + \frac{\Delta r^4}{12}\left(\frac{\partial^4 y}{\partial
            r^4}\right)_j + O(\Delta r^6) }{\Delta r^2} + \frac{ 2\Delta r \left(\frac{\partial y}{
            \partial r}\right)_j + \frac{\Delta r^3}{3}\left(\frac{\partial^3 y}{\partial
            r^3}\right)_j + O(\Delta r^5) }{2r_j\Delta r} \\
            \tau_j = \Delta r^2 \left(\frac{1}{12}\left(\frac{\partial^4 y}{\partial
            r^4}\right)_j + \frac{1}{6r_j}\left(\frac{\partial^3 y}{\partial
            r^3}\right)_j + h.o.t\right)
        \end{align*}
        Thus we find that this scheme as expected (it being a second order
        finite difference scheme) is in fact a second ordered finite difference
        scheme. 
    \end{proof}
\end{enumerate}

\end{document}
